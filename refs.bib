@misc{PyTorchDCGANTutorial,
  author = {{N}athan {I}nkawhich},
  title = {DCGAN Tutorial},
  year = {2023},
  Note = {Disponível em: \url{https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html}},
  organization = {PyTorch}
}



@misc{StyleGAN2,
  doi = {10.48550/ARXIV.1912.04958},
  url = {https://arxiv.org/abs/1912.04958},
  author = {Karras,  Tero and Laine,  Samuli and Aittala,  Miika and Hellsten,  Janne and Lehtinen,  Jaakko and Aila,  Timo},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  Machine Learning (cs.LG),  Neural and Evolutionary Computing (cs.NE),  Image and Video Processing (eess.IV),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering},
  title = {Analyzing and Improving the Image Quality of StyleGAN},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}



@misc{LSUN,
  doi = {10.48550/ARXIV.1506.03365},
  url = {https://arxiv.org/abs/1506.03365},
  author = {Yu,  Fisher and Seff,  Ari and Zhang,  Yinda and Song,  Shuran and Funkhouser,  Thomas and Xiao,  Jianxiong},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}


@misc{Li:2022,
  doi = {10.48550/ARXIV.2207.10077},
  url = {https://arxiv.org/abs/2207.10077},
  author = {Li,  Zhiheng and Hoogs,  Anthony and Xu,  Chenliang},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  Computers and Society (cs.CY),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Discover and Mitigate Unknown Biases with Debiasing Alternate Networks},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{Li:2021,
  doi = {10.48550/ARXIV.2104.14556},
  url = {https://arxiv.org/abs/2104.14556},
  author = {Li,  Zhiheng and Xu,  Chenliang},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Discover the Unknown Biased Attribute of an Image Classifier},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{Ingle2020,
  author = {Ingle, Atharva},
  title = {{P}lant {D}isease {C}lassification - {R}es{N}et- 99.2%},
  year = {2023},
  howpublished = {Kaggle},
  note = {Disponível em: \url{https://www.kaggle.com/code/atharvaingle/plant-disease-classification-resnet-99-2}}
}

@misc{RomeroPlantDiseasesClassifier,
  author = {Romero, Viridiana},
  title = {Plant Diseases Classifier},
  year = {2019},
  howpublished = {Repositório do GitHub},
  note = {Disponível em: \url{https://github.com/viritaromero/Plant-diseases-classifier/blob/master/Plant_diseased_classifier.ipynb}}
}

@article{Mohanty2016,
  doi = {10.3389/fpls.2016.01419},
  url = {https://doi.org/10.3389/fpls.2016.01419},
  year = {2016},
  month = sep,
  publisher = {Frontiers Media {SA}},
  volume = {7},
  author = {Sharada P. Mohanty and David P. Hughes and Marcel Salath{\'{e}}},
  title = {Using Deep Learning for Image-Based Plant Disease Detection},
  journal = {Frontiers in Plant Science}
}


@misc{Rath:2023,
  author = {Rath, Sovit},
  title = {{P}lant{V}illage {D}ataset {D}isease {R}ecognition using {P}yTorch},
  note = {Disponível em: \url{https://debuggercafe.com/plantvillage-dataset-disease-recognition-using-pytorch/}},
  Year = {2023},
}

@misc{Hinton:2012,
Author = {Geoffrey E. Hinton and Nitish Srivastava and Alex Krizhevsky and Ilya Sutskever and Ruslan R. Salakhutdinov},
Title = {Improving neural networks by preventing co-adaptation of feature detectors},
Year = {2012},
Eprint = {arXiv:1207.0580},
}

@misc{Noyan:2022,
Author = {Mehmet Alican Noyan},
Title = {Uncovering bias in the PlantVillage dataset},
Year = {2022},
Eprint = {arXiv:2206.04374},
}


@article{VGGNet,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1409.1556},
  year      = {2014},
  archivePrefix = {arXiv},
  eprint    = {1409.1556},
  timestamp = {Wed, 07 Jun 2017 14:41:51 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@INPROCEEDINGS{GoogleLeNet,
author={C. Szegedy and Wei Liu and Yangqing Jia and P. Sermanet and S. Reed and D. Anguelov and D. Erhan and V. Vanhoucke and A. Rabinovich},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Going deeper with convolutions},
year={2015},
volume={},
number={},
pages={1-9},
ISSN={1063-6919},
month={June},
OPTNote = {inception module}
}

@INPROCEEDINGS{ResNet,
author={K. He and X. Zhang and S. Ren and J. Sun},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Deep Residual Learning for Image Recognition},
year={2016},
volume={},
number={},
pages={770-778},
ISSN={},
month={June},}

@article{Bock:2022,
  author = {C. H. Bock and Kuo-Szu Chiang and Emerson M. Del Ponte},
  title = {Plant disease severity estimated visually: a century of research, best practices, and opportunities for improving methods and practices to maximize accuracy},
  journal = {Tropical Plant Pathology},
  volume = {47},
  pages = {25-42},
  year  = {2022},
  publisher = {},
  doi = {10.1007/s40858-021-00439-z},
}

@article{Bock:2010,
  author = {C. H. Bock  and  G. H.   Poole  and  P. E.   Parker  and  T. R.   Gottwald },
  title = {Plant Disease Severity Estimated Visually, by Digital Photography and Image Analysis, and by Hyperspectral Imaging},
  journal = {Critical Reviews in Plant Sciences},
  volume = {29},
  number = {2},
  pages = {59-107},
  year  = {2010},
  publisher = {Taylor & Francis},
  doi = {10.1080/07352681003617285},
  URL = {https://doi.org/10.1080/07352681003617285}
}

@inproceedings{Dosovitskiy:2021,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  booktitle = {{ICLR}},
  publisher = {OpenReview.net},
  year      = {2021}
}

@inproceedings{Bahdanau:2015,
  author    = {Dzmitry Bahdanau and
               Kyunghyun Cho and
               Yoshua Bengio},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  booktitle = {{ICLR}},
  year      = {2015}
}

@inproceedings{Vaswani:2017,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, \L{}ukasz and Polosukhin, Illia},
  title = {Attention is All You Need},
  year = {2017},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages = {6000–6010},
  series = {NIPS'17}
}

@inproceedings{Krizhevsky:2012,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}




@INPROCEEDINGS{SWIN:2021,
  author = {Z. Liu and Y. Lin and Y. Cao and H. Hu and Y. Wei and Z. Zhang and S. Lin and B. Guo},
  booktitle = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  title = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  year = {2021},
  volume = {},
  issn = {},
  pages = {9992-10002},
  doi = {10.1109/ICCV48922.2021.00986},
  url = {https://doi.ieeecomputersociety.org/10.1109/ICCV48922.2021.00986},
  publisher = {IEEE Computer Society},
  address = {Los Alamitos, CA, USA},
  month = {oct}
}

@Book{Nielsen:2015,
  author = 	 {Michael A. Nielsen},
  ALTeditor = 	 {},
  title = 	 {Neural Networks and Deep Learning},
  publisher = 	 {Determination Press},
  year = 	 {2015}
}


@Book{GonzWood:02,
  author =       "R. C. Gonzalez and R. E. Woods",
  title =        "Digital Image Processing",
  publisher =    "Addison-Wesley Publishing Company",
  year =         "2002",
  edition =      {Second}  
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@Book{Prince:2012,
  author = 	 {Simon D. J. Prince},
  ALTeditor = 	 {},
  title = 	 {Computer Vision -- Models, Learning and Inference},
  publisher = 	 {Cambridge},
  year = 	 {2012},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTedition = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {}
}

@Book{Szeliski:2011,
  author = 	 {R. Szeliski},
  title = 	 {Computer Vision -- Algorithms and Applications},
  publisher = 	 {Springer},
  year = 	 {2011},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTedition = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {}
}



@Book{Yaser:2012,
  author = 	 {Yaser S. Abu-Mostafa and Hsuan-Tien Lin and Malik Magdon-Ismail},
  title = 	 {Learning From Data},
  publisher = 	 {AMLBook},
  year = 	 {2012}
}

@book{pml1Book,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: An introduction",
 publisher = "MIT Press",
 year = 2022,
 url = "probml.ai"
}

@article{Geetharamani2019,
title = {Identification of plant leaf diseases using a nine-layer deep convolutional neural network},
journal = {Computers \& Electrical Engineering},
volume = {76},
pages = {323-338},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0045790619300023},
author = {Geetharamani, G. and Arun Pandian, J.},
keywords = {Artificial intelligence, Deep convolutional neural networks, Deep learning, Dropout, Image augmentation, Leaf diseases identification, Machine learning, Mini batch, Training epoch, Transfer learning},
abstract = {In this paper, we proposed a novel plant leaf disease identification model based on a deep convolutional neural network (Deep CNN). The Deep CNN model is trained using an open dataset with 39 different classes of plant leaves and background images. Six types of data augmentation methods were used: image flipping, gamma correction, noise injection, principal component analysis (PCA) colour augmentation, rotation, and scaling. We observed that using data augmentation can increase the performance of the model. The proposed model was trained using different training epochs, batch sizes and dropouts. Compared with popular transfer learning approaches, the proposed model achieves better performance when using the validation data. After an extensive simulation, the proposed model achieves 96.46\% classification accuracy. This accuracy of the proposed work is greater than the accuracy of traditional machine learning approaches. The proposed model is also tested with respect to its consistency and reliability.}
}

@INPROCEEDINGS{LeCun:2010,

  author={LeCun, Yann and Kavukcuoglu, Koray and Farabet, Clement},

  booktitle={Proceedings of 2010 IEEE International Symposium on Circuits and Systems}, 

  title={Convolutional networks and applications in vision}, 

  year={2010},

  volume={},

  number={},

  pages={253-256},

  doi={10.1109/ISCAS.2010.5537907}}







@misc{plantxvit,
  doi = {10.48550/ARXIV.2207.07919},
  
  url = {https://arxiv.org/abs/2207.07919},
  
  author = {Thakur, Poornima Singh and Khanna, Pritee and Sheorey, Tanuja and Ojha, Aparajita},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Explainable vision transformer enabled convolutional neural network for plant disease identification: PlantXViT},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@Article{Borhani2022,
author={Borhani, Yasamin
and Khoramdel, Javad
and Najafi, Esmaeil},
title={A deep learning based approach for automated plant disease classification using vision transformer},
journal={Scientific Reports},
year={2022},
month={Jul},
day={07},
volume={12},
number={1},
pages={11554},
abstract={Plant disease can diminish a considerable portion of the agricultural products on each farm. The main goal of this work is to provide visual information for the farmers to enable them to take the necessary preventive measures. A lightweight deep learning approach is proposed based on the Vision Transformer (ViT) for real-time automated plant disease classification. In addition to the ViT, the classical convolutional neural network (CNN) methods and the combination of CNN and ViT have been implemented for the plant disease classification. The models have been trained and evaluated on multiple datasets. Based on the comparison between the obtained results, it is concluded that although attention blocks increase the accuracy, they decelerate the prediction. Combining attention blocks with CNN blocks can compensate for the speed.},
issn={2045-2322},
doi={10.1038/s41598-022-15163-0},
url={https://doi.org/10.1038/s41598-022-15163-0}
}

@article{HughesS15,
  author    = {David P. Hughes and
               Marcel Salath{\'{e} } },
  title     = {An open access repository of images on plant health to enable the
               development of mobile disease diagnostics through machine
               learning and crowdsourcing},
  journal   = {CoRR},
  volume    = {abs/1511.08060},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.08060},
  archivePrefix = {arXiv},
  eprint    = {1511.08060},
  timestamp = {Mon, 13 Aug 2018 16:48:21 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HughesS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Mohanty:2016,
  AUTHOR={Mohanty, Sharada P. and Hughes, David P. and Salathé, Marcel},   
	 TITLE={Using Deep Learning for Image-Based Plant Disease Detection},
  JOURNAL={Frontiers in Plant Science},     
  VOLUME={7},           
  YEAR={2016},      
  URL={https://www.frontiersin.org/articles/10.3389/fpls.2016.01419},       DOI={10.3389/fpls.2016.01419},
  ISSN={1664-462X},   
  ABSTRACT={Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35\% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.}
}

@article{Singh:2017,
  title = {Detection of plant leaf diseases using image segmentation and soft computing techniques},
  journal = {Information Processing in Agriculture},
  volume = {4},
  number = {1},
  pages = {41-49},
  year = {2017},
  issn = {2214-3173},
  doi = {https://doi.org/10.1016/j.inpa.2016.10.005},
  url = {https://www.sciencedirect.com/science/article/pii/S2214317316300154},
  author = {Vijai Singh and A.K. Misra},
  keywords = {Image processing, Genetic algorithm, Plant disease detection, Classification},
  abstract = {Agricultural productivity is something on which economy highly depends. This is the one of the reasons that disease detection in plants plays an important role in agriculture field, as having disease in plants are quite natural. If proper care is not taken in this area then it causes serious effects on plants and due to which respective product quality, quantity or productivity is affected. For instance a disease named little leaf disease is a hazardous disease found in pine trees in United States. Detection of plant disease through some automatic technique is beneficial as it reduces a large work of monitoring in big farms of crops, and at very early stage itself it detects the symptoms of diseases i.e. when they appear on plant leaves. This paper presents an algorithm for image segmentation technique which is used for automatic detection and classification of plant leaf diseases. It also covers survey on different diseases classification techniques that can be used for plant leaf disease detection. Image segmentation, which is an important aspect for disease detection in plant leaf disease, is done by using genetic algorithm.}
}

@article{Mahlein:2016,
  author = {Mahlein, Anne-Katrin},
  title = {Plant Disease Detection by Imaging Sensors – Parallels and Specific Demands for Precision Agriculture and Plant Phenotyping},
  journal = {Plant Disease},
  volume = {100},
  number = {2},
  pages = {241-251},
  year = {2016},
  doi = {10.1094/PDIS-03-15-0340-FE},
  note ={PMID: 30694129},
  URL = {https://doi.org/10.1094/PDIS-03-15-0340-FE},
  eprint = {https://doi.org/10.1094/PDIS-03-15-0340-FE},
  abstract = { Early and accurate detection and diagnosis of plant diseases are key factors in plant production and the reduction of both qualitative and quantitative losses in crop yield. Optical techniques, such as RGB imaging, multi- and hyperspectral sensors, thermography, or chlorophyll fluorescence, have proven their potential in automated, objective, and reproducible detection systems for the identification and quantification of plant diseases at early time points in epidemics. Recently, 3D scanning has also been added as an optical analysis that supplies additional information on crop plant vitality. Different platforms from proximal to remote sensing are available for multiscale monitoring of single crop organs or entire fields. Accurate and reliable detection of diseases is facilitated by highly sophisticated and innovative methods of data analysis that lead to new insights derived from sensor data for complex plant-pathogen systems. Nondestructive, sensor-based methods support and expand upon visual and/or molecular approaches to plant disease assessment. The most relevant areas of application of sensor-based analyses are precision agriculture and plant phenotyping. }
}


@book{FAO:2021,
 author  = {{IPPC Secretariat}},
 title   = {Scientific review of the impact of climate change on plant pests – {A} global challenge to prevent and mitigate plant pest risks in agriculture, forestry and ecosystems},
 year    = {2021},
 address = {Rome},
 publisher = {FAO on behalf of the IPPC Secretariat},
 doi = {https://doi.org/10.4060/cb4769en}
}

@techreport{CitekeyTechreport,
  title       = "{W}asatch {S}olar {P}roject Final Report",
  author      = "Bennett, Vicki and Bowman, Kate and Wright, Sarah",
  institution = "Salt Lake City Corporation",
  address     = "Salt Lake City, UT",
  number      = "DOE-SLC-6903-1",
  year        = 2018,
  month       = sep
}


IPPC Secretariat. 2021. Scientific review of the impact of climate change on plant pests – A global challenge to prevent and mitigate plant pest risks in agriculture, forestry and ecosystems. Rome. FAO on behalf of the IPPC Secretariat.
https://doi.org/10.4060/cb4769en



@inproceedings{afifi2019color,
  title={When Color Constancy Goes Wrong: Correcting Improperly White-Balanced Images},
  author={Afifi, Mahmoud and Price, Brian and Cohen, Scott and Brown, Michael S},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1535--1544},
  year={2019}
}

@inproceedings{afifi2021learning,
  title={Learning Multi-Scale Photo Exposure Correction},
  author={Afifi, Mahmoud and Derpanis, Konstantinos G and Ommer, Bj{\"o}rn and Brown, Michael S},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2021}
}

@misc{prograde_histogram,
    author = {{ProGrade Digital}},
    title = {Understanding the Histogram Graph on Your Camera},
    year = {2024},
    howpublished = {\url{https://progradedigital.com/understanding-the-histogram-graph-on-your-camera/}},
    note = {Acessado em: 03 de Junho de 2024}
}


@misc{gatis2024rembg,
    author = {Daniel Gatis},
    title = {rembg},
    year = {2024},
    howpublished = {\url{https://github.com/danielgatis/rembg}},
    note = {Acessado em: 03 de Junho de 2024}
}

@article{maaten2008visualizing,
  title={Visualizing data using t-SNE},
  author={Maaten, Laurens van der and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={Nov},
  pages={2579--2605},
  year={2008}
}

@article{Badue2019Self-Driving,
title={Self-Driving Cars: A Survey},
author={C. Badue and Rânik Guidolini and Raphael V. Carneiro and Pedro Azevedo and Vinicius B. Cardoso and Avelino Forechi and Luan F. R. Jesus and Rodrigo Berriel and T. M. Paixão and Filipe Wall Mutz and Thiago Oliveira-Santos and A. D. Souza},
journal={ArXiv},
year={2019},
volume={abs/1901.04407},
doi={10.1016/j.eswa.2020.113816}
}

@misc{LLMsScience,
  doi = {10.48550/ARXIV.2311.07361},
  url = {https://arxiv.org/abs/2311.07361},
  author = {AI4Science,  Microsoft Research and Quantum,  Microsoft Azure},
  keywords = {Computation and Language (cs.CL),  Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{Minaee:2024,
  doi = {10.48550/ARXIV.2402.06196},
  url = {https://arxiv.org/abs/2402.06196},
  author = {Minaee,  Shervin and Mikolov,  Tomas and Nikzad,  Narjes and Chenaghlu,  Meysam and Socher,  Richard and Amatriain,  Xavier and Gao,  Jianfeng},
  keywords = {Computation and Language (cs.CL),  Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Large Language Models: A Survey},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{Yao2023,
  title = {Machine learning for leaf disease classification: data,  techniques and applications},
  volume = {56},
  ISSN = {1573-7462},
  url = {http://dx.doi.org/10.1007/s10462-023-10610-4},
  DOI = {10.1007/s10462-023-10610-4},
  number = {S3},
  journal = {Artificial Intelligence Review},
  publisher = {Springer Science and Business Media LLC},
  author = {Yao,  Jianping and Tran,  Son N. and Sawyer,  Samantha and Garg,  Saurabh},
  year = {2023},
  month = oct,
  pages = {3571–3616}
}

@inproceedings{Singh2020,
  series = {CoDS COMAD 2020},
  title = {PlantDoc: A Dataset for Visual Plant Disease Detection},
  url = {http://dx.doi.org/10.1145/3371158.3371196},
  DOI = {10.1145/3371158.3371196},
  booktitle = {Proceedings of the 7th ACM IKDD CoDS and 25th COMAD},
  publisher = {ACM},
  author = {Singh,  Davinder and Jain,  Naman and Jain,  Pranjali and Kayal,  Pratik and Kumawat,  Sudhakar and Batra,  Nipun},
  year = {2020},
  month = jan,
  collection = {CoDS COMAD 2020}
}

@article{Coletta2022Optimal,
title={Optimal Deployment in Crowdsensing for Plant Disease Diagnosis in Developing Countries},
author={Andrea Coletta and N. Bartolini and G. Maselli and Annalyse Kehs and Peter McCloskey and David P. Hughes},
journal={IEEE Internet of Things Journal},
year={2022},
volume={9},
pages={6359-6373},
doi={10.1109/jiot.2020.3002332}
}

@article{Siddiqua2022,
  title = {Evaluating Plant Disease Detection Mobile Applications: Quality and Limitations},
  volume = {12},
  ISSN = {2073-4395},
  url = {http://dx.doi.org/10.3390/agronomy12081869},
  DOI = {10.3390/agronomy12081869},
  number = {8},
  journal = {Agronomy},
  publisher = {MDPI AG},
  author = {Siddiqua,  Ayesha and Kabir,  Muhammad Ashad and Ferdous,  Tanzina and Ali,  Israt Bintea and Weston,  Leslie A.},
  year = {2022},
  month = aug,
  pages = {1869}
}

@article{Shorten2019A,title={A survey on Image Data Augmentation for Deep Learning},author={Connor Shorten and T. Khoshgoftaar},journal={Journal of Big Data},year={2019},volume={6},pages={1-48},doi={10.1186/s40537-019-0197-0}}

@article{Barz2019Do,title={Do We Train on Test Data? Purging CIFAR of Near-Duplicates},author={Björn Barz and Joachim Denzler},journal={Journal of Imaging},year={2019},volume={6},doi={10.3390/jimaging6060041}}

@article{Zou2019Object,
title={Object Detection in 20 Years: A Survey},
author={Zhengxia Zou and Zhenwei Shi and Yuhong Guo and Jieping Ye},
journal={Proceedings of the IEEE},
year={2019},
volume={111},
pages={257-276},
doi={10.1109/JPROC.2023.3238524}
}

@article{Zhao2018Object,
title={Object Detection With Deep Learning: A Review},
author={Zhong-Qiu Zhao and Peng Zheng and Shou-tao Xu and Xindong Wu},
journal={IEEE Transactions on Neural Networks and Learning Systems},
year={2018},
volume={30},
pages={3212-3232},
doi={10.1109/TNNLS.2018.2876865}
}

@INPROCEEDINGS{Viola,
  author={Viola, P. and Jones, M.},
  booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001}, 
  title={Rapid object detection using a boosted cascade of simple features}, 
  year={2001},
  volume={1},
  number={},
  pages={I-I},
  keywords={Object detection;Face detection;Pixel;Detectors;Filters;Machine learning;Image representation;Focusing;Skin;Robustness},
  doi={10.1109/CVPR.2001.990517}}

@INPROCEEDINGS{HOG,
  author={Dalal, N. and Triggs, B.},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={Histograms of oriented gradients for human detection}, 
  year={2005},
  volume={1},
  number={},
  pages={886-893 vol. 1},
  keywords={Histograms;Humans;Robustness;Object recognition;Support vector machines;Object detection;Testing;Image edge detection;High performance computing;Image databases},
  doi={10.1109/CVPR.2005.177}}

@misc{klemmer2016,
  author       = {Klemmer, Scott R.},
  title        = {Lecture 8: Storyboarding},
  year         = {2016},
  note         = {Adapted from Amal Dar Aziz, Guide to Storyboarding},
  journal = {\url{https://courses.cs.washington.edu/courses/cse440/15au/slides/lecture/l08-storyboarding.pdf}},
  institution  = {University of Washington, CSE 440: Introduction to Human-Centered Design}
}

@INPROCEEDINGS{rcnn1,

  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},

  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 

  title={Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation}, 

  year={2014},

  volume={},

  number={},

  pages={580-587},

  keywords={Proposals;Feature extraction;Training;Visualization;Object detection;Vectors;Support vector machines},

  doi={10.1109/CVPR.2014.81}}


@ARTICLE{rcnn2,
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Region-Based Convolutional Networks for Accurate Object Detection and Segmentation}, 
  year={2016},
  volume={38},
  number={1},
  pages={142-158},
  keywords={Proposals;Object detection;Feature extraction;Training;Image segmentation;Support vector machines;Detectors;Object recognition;detection;semantic segmentation;convolutional networks;deep learning;transfer learning;Object recognition;detection;semantic segmentation;convolutional networks;deep learning;transfer learning},
  doi={10.1109/TPAMI.2015.2437384}}

@article{Cortes1995Support-Vector,
title={Support-Vector Networks},
author={Corinna Cortes and V. Vapnik},
journal={Machine Learning},
year={1995},
volume={20},
pages={273-297},
doi={10.1023/A:1022627411411}
}

@article{SPPNet,
title={Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition},
author={Kaiming He and X. Zhang and Shaoqing Ren and Jian Sun},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
year={2014},
volume={37},
pages={1904-1916},
doi={10.1007/978-3-319-10578-9_23}
}

@INPROCEEDINGS{fastRCNN,
  author={Girshick, Ross},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Fast R-CNN}, 
  year={2015},
  volume={},
  number={},
  pages={1440-1448},
  keywords={Training;Proposals;Feature extraction;Object detection;Pipelines;Computer architecture;Open source software},
  doi={10.1109/ICCV.2015.169}}


@misc{MTheiler,
  author = {MTheiler},
  title = {Bounding boxes in object detection},
  howpublished = {\url{https://commons.wikimedia.org/w/index.php?curid=75843378}},
  year = {2019},
  note = {CC BY-SA 4.0}
}

@INPROCEEDINGS{yolo,
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={You Only Look Once: Unified, Real-Time Object Detection}, 
  year={2016},
  volume={},
  number={},
  pages={779-788},
  keywords={Computer architecture;Microprocessors;Object detection;Training;Real-time systems;Neural networks;Pipelines},
  doi={10.1109/CVPR.2016.91}}

@misc{yolov8_2023,
  author = {Ultralytics},
  title = {YOLOv8: A State-of-the-Art Object Detection Model},
  year = {2023},
  url = {https://github.com/ultralytics/ultralytics},
  note = {Accessed: 2024-10-30}
}

@misc{yolo11_2024,
  author = {Ultralytics},
  title = {Ultralytics YOLO11},
  year = {2024},
  url = {https://github.com/ultralytics/ultralytics},
  note = {Accessed: 2024-10-30}
}


@Article{yolo_review,
AUTHOR = {Terven, Juan and Córdova-Esparza, Diana-Margarita and Romero-González, Julio-Alejandro},
TITLE = {A Comprehensive Review of YOLO Architectures in Computer Vision: From YOLOv1 to YOLOv8 and YOLO-NAS},
JOURNAL = {Machine Learning and Knowledge Extraction},
VOLUME = {5},
YEAR = {2023},
NUMBER = {4},
PAGES = {1680--1716},
URL = {https://www.mdpi.com/2504-4990/5/4/83},
ISSN = {2504-4990},
ABSTRACT = {YOLO has become a central real-time object detection system for robotics, driverless cars, and video monitoring applications. We present a comprehensive analysis of YOLO’s evolution, examining the innovations and contributions in each iteration from the original YOLO up to YOLOv8, YOLO-NAS, and YOLO with transformers. We start by describing the standard metrics and postprocessing; then, we discuss the major changes in network architecture and training tricks for each model. Finally, we summarize the essential lessons from YOLO’s development and provide a perspective on its future, highlighting potential research directions to enhance real-time object detection systems.},
DOI = {10.3390/make5040083}
}


@misc{yolox2021,
  doi = {10.48550/ARXIV.2107.08430},
  url = {https://arxiv.org/abs/2107.08430},
  author = {Ge,  Zheng and Liu,  Songtao and Wang,  Feng and Li,  Zeming and Sun,  Jian},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {YOLOX: Exceeding YOLO Series in 2021},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{ultralytics_yolov8_results,
  author = {Ultralytics},
  title = {YOLOv8 Models Documentation},
  year = {2023},
  url = {https://docs.ultralytics.com/models/yolov8/#__tabbed_1_1},
  note = {Accessed: 2023-10-10}
}


@misc{ultralytics_issue_189,
  author = {Range King},
  title = {Brief summary of YOLOv8 model structure},
  year = {2023},
  url = {https://github.com/ultralytics/ultralytics/issues/189},
  note = {Accessed: 2023-10-10}
}

@INPROCEEDINGS{googlenet,
  author={Szegedy, Christian and Wei Liu and Yangqing Jia and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Going deeper with convolutions}, 
  year={2015},
  volume={},
  number={},
  pages={1-9},
  keywords={Computer architecture;Convolutional codes;Sparse matrices;Neural networks;Visualization;Object detection;Computer vision},
  doi={10.1109/CVPR.2015.7298594}}

@INPROCEEDINGS{imagenet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi={10.1109/CVPR.2009.5206848}}

@misc{Li2020,
  doi = {10.48550/ARXIV.2006.04388},
  url = {https://arxiv.org/abs/2006.04388},
  author = {Li,  Xiang and Wang,  Wenhai and Wu,  Lijun and Chen,  Shuo and Hu,  Xiaolin and Li,  Jun and Tang,  Jinhui and Yang,  Jian},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@article{Zheng2020,
  title = {Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression},
  volume = {34},
  ISSN = {2159-5399},
  url = {http://dx.doi.org/10.1609/aaai.v34i07.6999},
  DOI = {10.1609/aaai.v34i07.6999},
  number = {07},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  publisher = {Association for the Advancement of Artificial Intelligence (AAAI)},
  author = {Zheng,  Zhaohui and Wang,  Ping and Liu,  Wei and Li,  Jinze and Ye,  Rongguang and Ren,  Dongwei},
  year = {2020},
  month = apr,
  pages = {12993–13000}
}

@misc{shroff2021know,
  author = {Shroff, Megha},
  title = {Know your Neural Network Architecture More by Understanding These Terms},
  year = {2021},
  url = {https://medium.com/@shroffmegha6695/know-your-neural-network-architecture-more-by-understanding-these-terms-67faf4ea0efb},
  note = {Accessed: 2024-11-01}
}

@article{Padilla2020A,
title={A Survey on Performance Metrics for Object-Detection Algorithms},
author={Rafael Padilla and S. L. Netto and Eduardo A. B. da Silva},
journal={2020 International Conference on Systems, Signals and Image Processing (IWSSIP)},
year={2020},
pages={237-242},
doi={10.1109/IWSSIP48289.2020.9145130}
}


@misc{COCO,
  doi = {10.48550/ARXIV.1405.0312},
  url = {https://arxiv.org/abs/1405.0312},
  author = {Lin,  Tsung-Yi and Maire,  Michael and Belongie,  Serge and Bourdev,  Lubomir and Girshick,  Ross and Hays,  James and Perona,  Pietro and Ramanan,  Deva and Zitnick,  C. Lawrence and Dollár,  Piotr},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Microsoft COCO: Common Objects in Context},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}